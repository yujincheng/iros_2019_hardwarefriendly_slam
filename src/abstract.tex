Decentralized visual simultaneous localization and mapping (DSLAM) can share locations and environmental information between robots, which is an essential task for many multi-robot applications. For \textit{"robot"}, the Visual Odometry (VO) is a basic component to estimate the 6-DoF absolute pose, and for \textit{"multi"}, Decentralized Place Recognition (DPR) is a fundamental element to produce candidate place matches.
%Due to the advantages of Convolutional Neural Network(CNN) on image processing tasks, CNN-based VO and DPR have achieved significant improvements in performance., such as Depth-VO-Feat\cite{Zhan:2018e92} and NetVLAD\cite{Arandjelovic:2017997}. However, previous works concentrate on the accuracy of the CNNs, yet consider little about the deployment CNNs on the embedded system.
Although some CNN-based VO and DPR methods have made significant progress in performance compared to feature-based methods, such as Depth-VO-Feat \cite{Zhan:2018e92} and NetVLAD \cite{Arandjelovic:2017997}, they focus primarily  on the accuracy of CNNs, yet consider little about the deployment of CNNs on embedded systems.

Since the embedded system usually only supports fixed-point CNN, we propose a pose-sensitive fixed-point finetune method for the CNN-based monocular VO, and accelerate the per-frame VO from 230ms to 10ms with similar accuracy. In addition, empirical experiments show that the frequency of DPR has a large impact on the final result of DSLAM. So we propose a cross-component pipeline scheduling method to increase the computational speed of NetVLAD from once every 12 frames to once every 8 frames, and further improve the final accuracy of DSLAM.
% We find the tranditional average trajectory error (ATE) can not indicate the performance of trajectory merging in DSLAM, so we propose a new indicator called loop-closure recall (LCR) to evaluate the performance of trajectory merging.

% With the gradual improvement of the single-agent capabilities, it is possible to build up the multi-agent collaborative intelligence system.
% Distributed simultaneous localization and mapping (DSLAM) can share location and environmental information between robots and is the basis for many multi-agent applications.
% With the development of algorithms and computing platforms in recent years, convolutional neural network (CNN) has been widely used in SLAM systems, especially in visual-based SLAM systems.
% CNN can directly predict the pose with the absolute scale from two successive monocular frames, which can be easy to deploy on real robots and can make SLAM more robust in scenarios with pure rotations. Further, with CNN's versatility, it is easy to use the same network structure for many other tasks rather than depth or pose estimation, such as object detection and semantic segmentation.
% Finally, CNN's computational structure is uniform and can be individually optimized when resources are limited on embedded systems.

% In this work, we aim to build a fully CNN-based hardware-software co-design monocular DSLAM system. There are two keys components in DSLAM system: 1) Visual Odometry (VO) and 2) Place Recognition. We use fixed-point fine tune method to enhance the accuracy of CNN-based monocular VO and make it possible for acceleration on the Xilinx DPU accelerator. The same DPU also supports the place recognition component. We also propose a pipeline scheduling method to make full use of the DPU. To the best of our knowledge, this work is the first to implement all components of monocular DSLAM with CNN. We use the Xilinx ZU9 embedded MPSoC and the DPU IP core to validate the proposed DSLAM framework on the public dataset.